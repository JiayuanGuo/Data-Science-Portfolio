{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Web scraping with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this demo shows how to use BeautifulSoup to crawl job listing in indeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the necessary packages\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reach the link of jobs first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use indeed mobile web version (https://www.indeed.com/m/) since its html is simplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "viewjob?jk=8d11ab80a497e4bd\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=8d11ab80a497e4bd\n",
      "viewjob?jk=c5d25ae33dedf097\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=c5d25ae33dedf097\n",
      "viewjob?jk=ed0c4721f9b456bd\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=ed0c4721f9b456bd\n",
      "viewjob?jk=110b9c2db276db58\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=110b9c2db276db58\n",
      "viewjob?jk=193547a91e3c7357\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=193547a91e3c7357\n",
      "viewjob?jk=0610bd006c630479\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=0610bd006c630479\n",
      "viewjob?jk=ee6d5ddff98335ac\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=ee6d5ddff98335ac\n",
      "viewjob?jk=260ceedfb7f96549\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=260ceedfb7f96549\n",
      "viewjob?jk=e8fe83ac09c606ce\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=e8fe83ac09c606ce\n",
      "viewjob?jk=c61846f8b8f7017f\n",
      "<class 'str'>\n",
      "https://www.indeed.com/m/viewjob?jk=c61846f8b8f7017f\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "url = \"https://www.indeed.com/m/jobs?q=data+scientist&l=Los+Angeles%2C+CA\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "\n",
    "all_matches = soup.find_all('a', attrs={'rel':['nofollow']})\n",
    "for i in all_matches:\n",
    "    print (i['href'])\n",
    "    print (type(i['href']))\n",
    "    print (\"https://www.indeed.com/m/\"+i['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Find the title, company, location and detailed job description for each job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see a brief example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_html= \\\n",
    "'''\n",
    "<html>\n",
    "\t<body>\n",
    "\t\t<p>\n",
    "\t\t\t<b>\n",
    "\t\t\t\t<font size=\"+1\">Analyst - Data Science</font>\n",
    "\t\t\t</b>\n",
    "\t\t\t<br>The Boston Consulting Group - <span class=\"location\">Los Angeles, CA</span>\n",
    "\t\t</p>\n",
    "\t</body>\n",
    "</html>\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = BeautifulSoup(test_html,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyst - Data Science\n"
     ]
    }
   ],
   "source": [
    "print(bs.body.p.b.font.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Analyst - Data Science\n",
      "\n",
      "The Boston Consulting Group - Los Angeles, CA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bs.body.p.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los Angeles, CA\n"
     ]
    }
   ],
   "source": [
    "print(bs.body.p.span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find title, company, location and job description for one position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = []\n",
    "company = []\n",
    "location = []\n",
    "jd = []\n",
    "for each in all_matches:\n",
    "    jd_url= 'http://www.indeed.com/m/'+each['href']\n",
    "    jd_page = urlopen(jd_url)\n",
    "    jd_soup = BeautifulSoup(jd_page, 'lxml')\n",
    "    jd_desc = jd_soup.findAll('div',attrs={'id':['desc']}) ## find the structure like: <div id=\"desc\"></>\n",
    "#    break\n",
    "    title.append(jd_soup.body.p.b.font.text)\n",
    "    company.append(jd_desc[0].span.text)\n",
    "    location.append(jd_soup.body.p.span.text)\n",
    "    jd.append(jd_desc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hulu is a premium streaming TV destination that seeks to captivate and connect viewers with the stories they love. We create amazing experiences that celebrate the best of entertainment and technology. We’re looking for great people who are passionate about redefining TV through innovation, unconventional thinking and embracing fun. It’s a mission that takes some serious smarts, intense curiosity and determination to be the best. Come be part of the team that’s powering play. SUMMARY\n",
      "At Hulu, number one priority is our customers. We make business decisions around our customers’ preferences. Data Sciences Team at Hulu combines deep data analysis and research of our rich user data to present a compelling vision around user retention and preferences across the vast ecosystem of Hulu’s product offerings and content. We are looking for data scientists who are passionate about using data to drive strategy and product recommendations. You will be engaged with senior leaders to design well-constructed analyses and work cross-functionally with analysts, product managers and engineers to effectively deliver actionable results. You will work on variety of domains such as data science, machine learning and optimization; lead cutting edge analytical solution development pipeline and contribute to external research via attending conferences and collaborations. WHAT YOU’LL DO\n",
      "Apply state of the art machine learning, statistics or data mining in a variety of areas, including customer analysis, video content genome, social analysis, etc.\n",
      "Invent and fast iterate on novel solutions to challenging data related problems.\n",
      "Develop scalable and efficient methods for large scale data analyses and model development.\n",
      "Collaborate with developers, program managers, and product managers in an open, creative environment.\n",
      "Coaching and providing research and system guidance to a team of other researchers on a variety of areas including video content genome, social mining, data analysis, etc. WHAT TO BRING\n",
      "Master's degree in MS in Statistics or related quantitative field (e.g. Computer Science, Econometrics, Mathematics, Physics, Operations Research).\n",
      "3+ years related experience such as analyzing data and/or building analytical models; in either an academic or professional setting and 3+ years relevant work experience.\n",
      "Experienced with scripting languages such as R, Python, Ruby or SAS.\n",
      "Real world analytical solution building experience.\n",
      "Ability to draw conclusions from data and recommend actions.\n",
      "Demonstrated self-direction.\n",
      "Proficient in prototyping models using scripting languages (e.g. Python, Ruby, etc.). NICE-TO-HAVES\n",
      "PhD in in Statistics or related quantitative field (e.g. Econometrics, Mathematics, Physics, Operations Research).\n",
      "Experience in causal inference is a plus.\n",
      "\n",
      "We will consider for employment all qualified applicants, including those with criminal histories, in a manner consistent with applicable federal, state and local laws.\n",
      "\n",
      "LI-SY1\n",
      "\n",
      "\n",
      "Hulu - \n",
      "30+ days ago\n"
     ]
    }
   ],
   "source": [
    "## Job Description\n",
    "print(jd_desc[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist\n"
     ]
    }
   ],
   "source": [
    "## Job Title \n",
    "print(jd_soup.body.p.b.font.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hulu\n",
      "Hulu \n"
     ]
    }
   ],
   "source": [
    "## Company Name\n",
    "print(jd_desc[0].span.text)\n",
    "print(jd_soup.body.p.span.previous_sibling.split('-')[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data into Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job = {'title': title,\n",
    "         'company': company,\n",
    "         'location': location,\n",
    "         'Job Description': jd}\n",
    "df = pd.DataFrame.from_dict(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't break the loop above, we can crawl all the job information from one page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Change Pages Automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title = []\n",
    "company = []\n",
    "location = []\n",
    "jd = []\n",
    "url = \"https://www.indeed.com/m/jobs?q=data+scientist&l=Los+Angeles%2C+CA\"\n",
    "for i in range(2):\n",
    "    \n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    all_matches = soup.findAll(attrs={'rel':['nofollow']})\n",
    "    for each in all_matches:\n",
    "        jd_url= 'http://www.indeed.com/m/'+each['href']\n",
    "        jd_page =urlopen(jd_url)\n",
    "        jd_soup = BeautifulSoup(jd_page, 'lxml')\n",
    "        jd_desc = jd_soup.findAll(attrs={'id':['desc']})\n",
    "        title.append(jd_soup.body.p.b.font.text)\n",
    "        company.append(jd_desc[0].span.text)\n",
    "        location.append(jd_soup.body.p.span.text)\n",
    "        jd.append(jd_desc[0].text)\n",
    "        \n",
    "    ## Change the pages to Next Page\n",
    "    url_all = soup.findAll(attrs={'rel':['next']})\n",
    "    url = 'http://www.indeed.com/m/'+ str(url_all[0]['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job = {'title': title,\n",
    "         'company': company,\n",
    "         'location': location,\n",
    "         'Job Description': jd}\n",
    "df = pd.DataFrame.from_dict(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
